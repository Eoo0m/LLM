{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKlSZd4pSHf5",
        "outputId": "fce5d36e-d6bc-43b3-e2cb-d818e36be039"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "pldwZu-vSJPM",
        "outputId": "5b3f40e0-69bd-4d69-d2dd-178fabe92b79"
      },
      "outputs": [],
      "source": [
        "pip install datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3_A1SZDSVbv",
        "outputId": "78f60af8-75cf-4447-b56d-11a881a20627"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 파일 경로 (Google Drive 경로)\n",
        "csv_file_path = '/content/drive/MyDrive/data_file/train.csv'\n",
        "\n",
        "# 데이터 불러오기\n",
        "data = pd.read_csv(csv_file_path)\n",
        "\n",
        "# 데이터 확인\n",
        "print(data.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340,
          "referenced_widgets": [
            "458ad853f9dc4d0391434057ad4c1bff",
            "2e10f97ba3fb40318166dbaaf156cd94",
            "bce4c825b9c2436aa9b58f04b9a731a2",
            "0bd3b918c9ff4192bd59c55eb4aed2a2",
            "c2d6f855b6934332870d402c8a01bb96",
            "7c98ed7d91f7438b8c3cca88ca6c2808",
            "88f8d2c86969470ba6d8529dcd5248a5",
            "9559ff4a6ba2497083242bcf275a6450",
            "7452eb3e0e544417880fef43e75dd51a",
            "f52960ac04bb4c06b5a40ff14d1a93d5",
            "54cd51868f84467c91763bcfa4fb7fd6",
            "cb981356664c4d1b9d7ba2bddb59647d",
            "55c8f5db207546feb9ea142a02086edd",
            "266954ce353d40f2b5a63cc49882186f",
            "c67c958bb2df4ff7860de14bcc0fc6a6",
            "ddb6b3f6d02e4922a63a3fe189701a5b",
            "598cf331d54b4a5d8549d48a8a3e1ae4",
            "00319daf6ae44a039eb5e7355786813f",
            "65f4a398136a47798e227b167a8103b5",
            "f6dfee6471e8416381f548d374dae20b",
            "5c9bd9dabb2d45b7b6c92e65cc7b1953",
            "11f2d34a5aa643dfa90763d67e844695",
            "048c0a0190cb4bd6a31a43ca5b0efb49",
            "70c32aea6059475d92d583dbb7b53562",
            "a5b002aca1ee4daca53fb13bb0ce9e68",
            "b9570bffae2b4b27a302592d6dd3e858",
            "156a13d6b18a454ebefec9b1cda3e752",
            "6809e44b9d174f8eb4c973058e3641c5",
            "bbbc227a89bb433f8abc2b4386bf7edc",
            "5f685b560acb4e65a77f014e0b634db8",
            "38acc4ac5fca40eea1b2761294ff4b8f",
            "16a079d628cd442d9effad7430ae98ae",
            "dcfa119d179e4c5cb0533a565033b2fe",
            "f2cb322b15b34ca6a0b32e85a49eb65e",
            "ca39fa94165e47969f8bd470b851205f",
            "3e80763264db434aa9be4060b6d48f17",
            "9d754c3f83b94a59b398c6b7f217b247",
            "e33abe01b6484d4eb4f67d0afe580211",
            "003d713d407a48a186b968d6a250402a",
            "dd7fde3bfcc444fd954dd0df08a7414d",
            "4fab1983e9a743d2875df9a1baaa6f1b",
            "c935a3a8c8e54dff9d18b6b60a270c20",
            "c46e82755bff4171a524854d46152c73",
            "3397d59acdad4eff8390c5c15f1c8445",
            "eb6669ea81644afc88b45de896306664",
            "10ee96b6d85e41f2ae33fbadfd0f980a",
            "e3ea042e7d6442c682a53a4296ebeaa7",
            "62091fe3fec9438eb9d42ac95d53af0d",
            "72ca64190c1145a8868fe0bcac2263de",
            "f4a34b7f540542d8aa334ff6d2e4d42f",
            "8f019029a04440de9797bf2bc4f10ab0",
            "17ef5dcfe1f94a5aa8a4a231b80cd167",
            "06885d4cb5e84321acd2a5a7e19bf534",
            "cb884ea37ffe440d9e8de2d73f5999dd",
            "43e503c58faf44979610af5146cc1dd2",
            "ed51213a5d2c43aeb88a2c051af62df3",
            "8862672c20d24b3594337775bed78215",
            "091329e559354370810c29958be2535e",
            "68056c5f170a43b299c51d1ad40991c9",
            "e86d3225eda3490da785add66d395a65",
            "cd45f8f7b6204641beb65ffd880e67c2",
            "573984c34c314cfdb31026c516168a5c",
            "909e5e3e82864dc1ad09fd4876674d01",
            "445b22b858144512a55aca08037ede8f",
            "351f5d43e35241c28f1066a7fa9a3669",
            "8f9258702f5c498bac1536816c56b1bf"
          ]
        },
        "id": "1UiLVgxISS0y",
        "outputId": "1b648549-97d4-46c5-f047-682d3e142109"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, T5ForConditionalGeneration\n",
        "\n",
        "# 모델 이름 설정\n",
        "model_name = \"google/byt5-base\"\n",
        "\n",
        "# 모델 및 토크나이저 로드\n",
        "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ol_Mdf9MSi89"
      },
      "outputs": [],
      "source": [
        "# 데이터셋 나누기 (Hugging Face Datasets의 train_test_split 사용)\n",
        "dataset = tokenized_datasets  # 전체 데이터셋\n",
        "split = dataset.train_test_split(test_size=0.1, seed=42)\n",
        "\n",
        "# 나눠진 데이터셋\n",
        "dataset1 = split['train']\n",
        "dataset2 = split['test']\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "GFlWDzPk8Ea-",
        "outputId": "3ba3b980-8245-484e-ed58-9797cb336f29"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import TrainerCallback, Trainer, TrainingArguments\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoConfig\n",
        "\n",
        "model_name = \"google/byt5-base\"\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "\n",
        "# Dropout 설정 강제 적용\n",
        "model.config.dropout_rate = 0.4\n",
        "model.config.attention_probs_dropout_prob = 0.4\n",
        "model.config.activation_dropout = 0.4\n",
        "print(model.config)\n",
        "\n",
        "\n",
        "\n",
        "class CustomLoggerCallback(TrainerCallback):\n",
        "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
        "        if logs:\n",
        "            step = state.global_step\n",
        "            epoch = state.epoch\n",
        "\n",
        "        \n",
        "            lr = float(logs.get(\"learning_rate\", 0.0))  # 기본값 0.0\n",
        "            loss = float(logs.get(\"loss\", 0.0))  # 기본값 0.0\n",
        "            eval_loss = float(logs.get(\"eval_loss\", 0.0)) if \"eval_loss\" in logs else \"N/A\"  # eval_loss는 N/A 허용\n",
        "            grad_norm = float(logs.get(\"grad_norm\", 0.0))  # 기본값 0.0\n",
        "\n",
        "            print(f\"Step {step} | Epoch {epoch:.2f} | Loss: {loss:.4f} | Eval Loss: {eval_loss} | LR: {lr:.6f} | Grad Norm: {grad_norm:.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "new_output_dir = \"/content/drive/MyDrive/byt5base_dropout\" \n",
        "\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=new_output_dir,  \n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=5e-5,\n",
        "    per_device_train_batch_size=2,\n",
        "    per_device_eval_batch_size=4,\n",
        "    num_train_epochs=7,\n",
        "    weight_decay=0.02,\n",
        "    logging_steps=100,\n",
        "    log_level=\"info\",\n",
        "    logging_dir=\"./logs\",\n",
        "    bf16=True, \n",
        "    gradient_accumulation_steps=2, \n",
        "    max_grad_norm=1.0,  \n",
        ")\n",
        "\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=dataset1,\n",
        "    eval_dataset=dataset2,\n",
        "    callbacks=[CustomLoggerCallback()]\n",
        ")\n",
        "\n",
        "\n",
        "trainer.train()\n",
        "trainer.save_model(new_output_dir) \n",
        "trainer.state.save_to_json(os.path.join(new_output_dir, \"trainer_state.json\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsBiu1Adlmpw"
      },
      "source": [
        "dropout적용시킨후 lr도 올리기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "2L64yUJ9ljYv",
        "outputId": "bc5cb601-edc7-496b-aa3e-6b378dfa428f"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import TrainerCallback, Trainer, TrainingArguments\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoConfig\n",
        "\n",
        "model_name = \"google/byt5-base\"\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "\n",
        "# Dropout 설정 강제 적용\n",
        "model.config.dropout_rate = 0.4\n",
        "model.config.attention_probs_dropout_prob = 0.4\n",
        "model.config.activation_dropout = 0.4\n",
        "print(model.config)\n",
        "\n",
        "\n",
        "\n",
        "class CustomLoggerCallback(TrainerCallback):\n",
        "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
        "        if logs:\n",
        "            step = state.global_step\n",
        "            epoch = state.epoch\n",
        "            lr = float(logs.get(\"learning_rate\", 0.0))  # 기본값 0.0\n",
        "            loss = float(logs.get(\"loss\", 0.0))  # 기본값 0.0\n",
        "            eval_loss = float(logs.get(\"eval_loss\", 0.0)) if \"eval_loss\" in logs else \"N/A\"  # eval_loss는 N/A 허용\n",
        "            grad_norm = float(logs.get(\"grad_norm\", 0.0))  # 기본값 0.0\n",
        "\n",
        "            print(f\"Step {step} | Epoch {epoch:.2f} | Loss: {loss:.4f} | Eval Loss: {eval_loss} | LR: {lr:.6f} | Grad Norm: {grad_norm:.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "new_output_dir = \"/content/drive/MyDrive/byt5base_dropout3\" \\\n",
        "\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=new_output_dir, \\\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=2e-4,\n",
        "    per_device_train_batch_size=2,\n",
        "    per_device_eval_batch_size=4,\n",
        "    num_train_epochs=7,\n",
        "    weight_decay=0.02,\n",
        "    logging_steps=100,\n",
        "    log_level=\"info\",\n",
        "    logging_dir=\"./logs\",\n",
        "    bf16=True, \n",
        "    gradient_accumulation_steps=2,  \n",
        "    max_grad_norm=1.0,  \n",
        ")\n",
        "\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=dataset1,\n",
        "    eval_dataset=dataset2,\n",
        "    callbacks=[CustomLoggerCallback()]\n",
        ")\n",
        "\n",
        "\n",
        "trainer.train()\n",
        "trainer.save_model(new_output_dir)  # ✅ 새로운 폴더에 저장\n",
        "trainer.state.save_to_json(os.path.join(new_output_dir, \"trainer_state.json\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MEFvlEkpHYkB",
        "outputId": "de1964b8-deb4-4e51-fc7a-06973c58d812"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import T5ForConditionalGeneration, ByT5Tokenizer\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# GPU 최적화 설정\n",
        "torch.backends.cudnn.benchmark = True\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# 데이터 로드\n",
        "test_data_path = \"/content/drive/MyDrive/data_file/test.csv\"\n",
        "if not os.path.exists(test_data_path):\n",
        "    raise FileNotFoundError(f\"파일을 찾을 수 없습니다: {test_data_path}\")\n",
        "\n",
        "df_test = pd.read_csv(test_data_path)\n",
        "if \"input\" not in df_test.columns or \"ID\" not in df_test.columns:\n",
        "    raise ValueError(\"`test.csv` 파일에 `input` 또는 `ID` 컬럼이 없습니다.\")\n",
        "\n",
        "# 모델 로드 및 BF16 설정\n",
        "model_path = \"/content/drive/MyDrive/byt5base_dropout3/checkpoint-12670\"\n",
        "model = T5ForConditionalGeneration.from_pretrained(model_path).to(device).to(torch.bfloat16)\n",
        "tokenizer = ByT5Tokenizer.from_pretrained(\"google/byt5-base\")\n",
        "\n",
        "# 모델 연산 최적화\n",
        "model = torch.compile(model)\n",
        "model.eval()\n",
        "\n",
        "# 배치 크기 조정\n",
        "batch_size = 8\n",
        "total_size = len(df_test)\n",
        "\n",
        "# 결과 저장 리스트\n",
        "predictions = []\n",
        "\n",
        "# 배치 단위로 처리 (Beam Search 적용)\n",
        "for i in range(0, total_size, batch_size):\n",
        "    batch_texts = df_test[\"input\"].iloc[i: i + batch_size].tolist()\n",
        "\n",
        "    inputs = tokenizer(\n",
        "        batch_texts, return_tensors=\"pt\", padding=\"longest\", truncation=True, max_length=2096\n",
        "    ).to(device)\n",
        "\n",
        "    # BF16 적용 & Beam Search로 글로벌 최적해답 탐색\n",
        "    with torch.inference_mode(), torch.autocast(device_type=\"cuda\", dtype=torch.bfloat16):\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            num_beams=5,                \n",
        "            early_stopping=True,        \n",
        "            length_penalty=1.0,         \n",
        "            max_length=len(inputs[\"input_ids\"][0])  # 입력과 동일한 길이 유지\n",
        "        )\n",
        "\n",
        "    # 결과 디코딩 및 저장\n",
        "    batch_results = [tokenizer.decode(output, skip_special_tokens=True) for output in outputs]\n",
        "    predictions.extend(batch_results)\n",
        "\n",
        "    # 진행 상황 출력\n",
        "    progress = (i + batch_size) / total_size * 100\n",
        "    if i % (batch_size * 10) == 0 or i + batch_size >= total_size:\n",
        "        print(f\"🚀 Progress: {progress:.2f}% completed.\")\n",
        "\n",
        "# 예측 결과 저장\n",
        "df_test[\"output\"] = predictions\n",
        "submission_path = \"/content/drive/MyDrive/submission11.csv\"\n",
        "df_test[[\"ID\", \"output\"]].to_csv(submission_path, index=False, encoding=\"utf-8\")\n",
        "\n",
        "print(f\"✅ Submission file saved successfully: {submission_path}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
